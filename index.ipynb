{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%pip install -r requirments.txt --force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://colab.research.google.com/drive/1T3JjUyyaEUZN8hUVymyyvleDjR8ZJehE#scrollTo=lJY6Pz51PCM3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from flask_socketio import SocketIO, emit, join_room, leave_room\n",
    "from flask import *\n",
    "from flask_login import *\n",
    "from flask_session import Session\n",
    "from pypdf import PdfReader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "# from datetime import timedelta\n",
    "from langchain.chat_models import ChatOllama\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SMHRD\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n",
      "c:\\Users\\SMHRD\\anaconda3\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://192.168.219.51:5100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 9 0 (offset 0)\n",
      "Ignoring wrong pointing object 11 0 (offset 0)\n",
      "Ignoring wrong pointing object 21 0 (offset 0)\n",
      "Ignoring wrong pointing object 25 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SMHRD\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '자연어 처리 강사님을 확인해줘', 'chat_history': [HumanMessage(content='자연어 처리 강사님을 확인해줘'), AIMessage(content='민재홍  / Min JaehongR을 활용한  공공데이터  분석 강사입니다')], 'answer': '민재홍  / Min JaehongR을 활용한  공공데이터  분석 강사입니다'}\n",
      "processed\n",
      "{'question': '문서 내용을 바탕으로 보고서를 작성해야하는데 제목을 만들어줘', 'chat_history': [HumanMessage(content='문서 내용을 바탕으로 보고서를 작성해야하는데 제목을 만들어줘'), AIMessage(content='리버스 엔지니어링 주제 선정에 대한 안내입니다')], 'answer': '리버스 엔지니어링 주제 선정에 대한 안내입니다'}\n",
      "{'question': '보고서 목차를 만들어줘', 'chat_history': [HumanMessage(content='보고서 목차를 만들어줘'), AIMessage(content='1. 리버스 엔지니어링\\r\\n2. 전자 상거래\\r\\n3. 대시보드 (데이터 시각화)\\r\\n4. 챌린지 포인트 (OpenAI 사용')], 'answer': '1. 리버스 엔지니어링\\r\\n2. 전자 상거래\\r\\n3. 대시보드 (데이터 시각화)\\r\\n4. 챌린지 포인트 (OpenAI 사용'}\n"
     ]
    }
   ],
   "source": [
    "model = ChatOllama(model='meta-llama-3.1')\n",
    "#Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf\n",
    "#https://huggingface.co/lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/tree/main\n",
    "\n",
    "app = Flask(__name__)\n",
    "app.secret_key = \"mkqw2o0@#mk12!mk3\"\n",
    "\n",
    "app.config['SESSION_TYPE'] = 'filesystem' \n",
    "# app.config['SESSION_PERMANENT'] = False\n",
    "# app.config['SESSION_USE_SIGNER'] = True\n",
    "# app.config['SESSION_KEY_PREFIX'] = 'myapp_session:'\n",
    "Session(app)\n",
    "socketio = SocketIO(app)\n",
    "lm = LoginManager()\n",
    "lm.init_app(app)\n",
    "\n",
    "ngrok = ''\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-m3\",\n",
    "    model_kwargs = {'device': 'cpu'}, # 모델이 CPU에서 실행되도록 설정. GPU를 사용할 수 있는 환경이라면 'cuda'로 설정할 수도 있음\n",
    "    encode_kwargs = {'normalize_embeddings': True}, # 임베딩 정규화. 모든 벡터가 같은 범위의 값을 갖도록 함. 유사도 계산 시 일관성을 높여줌\n",
    ")\n",
    "\n",
    "@lm.user_loader\n",
    "def user_loader(userId):\n",
    "    userInfo = User.get_user_info(userId)\n",
    "    return User(userInfo)\n",
    "\n",
    "@lm.unauthorized_handler\n",
    "def unauthorized():\n",
    "    return redirect('/')\n",
    "\n",
    "#region CLASS\n",
    "\n",
    "class User(UserMixin):\n",
    "    def __init__(self, info):\n",
    "        self.info = info\n",
    "    \n",
    "    #region getter\n",
    "\n",
    "    def get_id(self):\n",
    "        return self.info['userId']\n",
    "\n",
    "    #endregion\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_user_info(userId):\n",
    "        return {'userId': userId}\n",
    "\n",
    "#endregion CLASS\n",
    "\n",
    "#region route\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/chatroom', methods = ['post'])\n",
    "def chatroom():\n",
    "    params = request.form\n",
    "    userId = params['userId']\n",
    "    roomId = params['roomId']\n",
    "    \n",
    "    session['userId'] = userId\n",
    "    session['roomId'] = roomId\n",
    "    \n",
    "    return render_template(\n",
    "        'chat.html',\n",
    "        userId = userId,\n",
    "        roomId = roomId\n",
    "    )\n",
    "\n",
    "@app.route('/chatbot')\n",
    "def chatbot():\n",
    "    if 'processed_pdf' in session:\n",
    "        return 'test msg'\n",
    "    return render_template('RAG.html')\n",
    "\n",
    "@app.route('/login', methods = ['post'])\n",
    "def login():\n",
    "    params = request.get_json()\n",
    "    userId = params['userId']\n",
    "    \n",
    "    userInfo = User.get_user_info(userId)\n",
    "    login_user(User(userInfo))\n",
    "    return jsonify({'result': 1})\n",
    "\n",
    "@app.route('/logout')\n",
    "def logout():\n",
    "    logout_user()\n",
    "    return redirect('/')\n",
    "\n",
    "@app.route('/pdfprocess', methods=['post'])\n",
    "def pdfprocess():\n",
    "    files = [request.files[i] for i in request.files]\n",
    "    \n",
    "    text_sum = ''\n",
    "    \n",
    "    for file in files:\n",
    "        reader = PdfReader(file)\n",
    "        for page in reader.pages: #페이지 별로 텍스트 추출\n",
    "            text = page.extract_text()\n",
    "            corrected_text = text.encode('utf-8', errors='ignore').decode('utf-8') #인코딩 오류 무시 및 텍스트 누적\n",
    "            text_sum += corrected_text +'\\n'\n",
    "\n",
    "    # print(text_sum)\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    splits = text_splitter.split_text(text_sum)\n",
    "    # print(splits)\n",
    "    vectorstore = FAISS.from_texts(\n",
    "        splits,\n",
    "        embedding = embedding_model\n",
    "    )\n",
    "    \n",
    "    vectorstore.save_local('test')\n",
    "    print('processed')\n",
    "    #region\n",
    "    \n",
    "    # reader = PdfReader(f)\n",
    "    # # 총 페이지 수 확인\n",
    "    # num_pages = len(reader.pages)\n",
    "\n",
    "    # # 모든 페이지 텍스트 추출\n",
    "    # all_text = \"\"\n",
    "    # for page_num in range(num_pages):\n",
    "    #     page = reader.pages[page_num]\n",
    "    #     text = page.extract_text()\n",
    "\n",
    "    #     # 인코딩 오류 무시 및 텍스트 누적\n",
    "    #     corrected_text = text.encode('utf-8', errors='ignore').decode('utf-8')\n",
    "    #     all_text += corrected_text + \"\\n\"  # 페이지 간 텍스트 구분을 위해 줄 바꿈 추가\n",
    "\n",
    "    # # 추출한 텍스트를 txt 파일로 저장\n",
    "    # output_file_path = './save.txt'\n",
    "    # with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "    #     output_file.write(all_text)\n",
    "    \n",
    "    #endregion\n",
    "    return jsonify({'result': 1})\n",
    "\n",
    "@app.route('/question', methods=['POST'])\n",
    "def question():\n",
    "    vectorstore = FAISS.load_local(\n",
    "        'test',\n",
    "        embedding_model,\n",
    "        allow_dangerous_deserialization=True,\n",
    "    )\n",
    "    params = request.get_json()\n",
    "    question = params['question']\n",
    "    \n",
    "    memory = ConversationBufferMemory(\n",
    "        memory_key='chat_history',\n",
    "        return_messages=True,\n",
    "    )\n",
    "\n",
    "    conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=model,\n",
    "        retriever=vectorstore.as_retriever(),\n",
    "        memory=memory,\n",
    "    )\n",
    "    res = conversation_chain({'question': question})\n",
    "    print(res)\n",
    "    \n",
    "    return jsonify({'result': res['chat_history'][1].content})\n",
    "\n",
    "#endregion route\n",
    "\n",
    "#region socket\n",
    "\n",
    "@socketio.on('joined', namespace = '/chatroom')\n",
    "def chat_joined(d):\n",
    "    roomId = session.get('roomId')\n",
    "    print(d, 'joined', roomId)\n",
    "    join_room(roomId)\n",
    "\n",
    "@socketio.on('msg', namespace = '/chatroom')\n",
    "def socket_msg(d):\n",
    "    roomId = session.get('roomId')\n",
    "    print('msg', d)\n",
    "    socketio.emit('msg', d, namespace = '/chatroom', room = roomId)\n",
    "\n",
    "#endregion socket\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print('http://192.168.219.51:5100')\n",
    "    socketio.run(app = app, host = '192.168.219.51', port = 5100, allow_unsafe_werkzeug = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
